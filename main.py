# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Z24H7actiVl6xbQ420jyZmBzbUG6MGv
"""

import pandas as pd
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, roc_curve
import numpy as np
import matplotlib.pyplot as plt
import shap
import lime
import lime.lime_tabular
from anchor import anchor_tabular

# Read the dataset
file_path = 'merged_genetic_data.xlsx'
df = pd.read_excel(file_path)

# Calculate the threshold for PHS
threshold = df['PHS'].median()
print(f"Threshold (Median): {threshold}")

# Categorize PHS values based on the threshold
df['PHS_Class'] = (df['PHS'] > threshold).astype(int)  # 1: High risk, 0: Low risk

# Fill missing values in numeric columns with the mean
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())

# Fill missing values in categorical columns with the mode
categorical_columns = df.select_dtypes(include=['object']).columns
for column in categorical_columns:
    df[column] = df[column].fillna(df[column].mode()[0])

# One-hot encode the categorical variables
encoder = OneHotEncoder(sparse=False, drop='first')
encoded_features = pd.DataFrame(encoder.fit_transform(df[categorical_columns]), columns=encoder.get_feature_names_out(categorical_columns))

# Remove the original categorical columns and add the encoded ones
df = df.drop(columns=categorical_columns)
df = pd.concat([df.reset_index(drop=True), encoded_features.reset_index(drop=True)], axis=1)

# Select features and target variable
X = df.drop(columns=['PHS', 'PHS_Class'])
y = df['PHS_Class']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# List of models to evaluate
models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'SVC': SVC(probability=True),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Decision Tree': DecisionTreeClassifier()
}

# Evaluate model performance
results = []
roc_curves = {}
recall_scores = {}

for model_name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]

    accuracy = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_prob)
    f1 = f1_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)

    # Calculate ROC curve values
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    roc_curves[model_name] = (fpr, tpr)
    recall_scores[model_name] = recall

    results.append([model_name, accuracy, roc_auc, f1, precision, recall])

# Display results in a table
results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'ROC AUC', 'F1 Score', 'Precision', 'Recall'])
print(results_df)

# Plot ROC curves
plt.figure(figsize=(10, 8))
for model_name, (fpr, tpr) in roc_curves.items():
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc_score(y_test, models[model_name].predict_proba(X_test_scaled)[:, 1]):.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves')
plt.legend(loc='best')
plt.savefig('roc_curves.png', dpi=300)
plt.show()

# Plot Recall scores
plt.figure(figsize=(10, 8))
model_names = list(recall_scores.keys())
recall_values = list(recall_scores.values())
plt.plot(model_names, recall_values, marker='o', linestyle='-', color='skyblue')
plt.xlabel('Models')
plt.ylabel('Recall')
plt.title('Recall Scores')
plt.savefig('recall_scores.png', dpi=300)
plt.show()

# SHAP explanations for the best model
model = GradientBoostingClassifier()
model.fit(X_train_scaled, y_train)

explainer = shap.Explainer(model, X_train_scaled)
shap_values = explainer(X_test_scaled)

plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, show=False)
plt.title('SHAP Summary Plot')
plt.savefig('shap_summary_plot.png', dpi=300)
plt.show()

# LIME explanation for a specific instance
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=np.array(X_train_scaled),
    feature_names=X.columns,
    class_names=['Low Risk', 'High Risk'],
    mode='classification'
)

instance_index = 0  # Change this to the index of the instance you want to visualize
exp = explainer.explain_instance(X_test_scaled[instance_index], model.predict_proba, num_features=10)

fig = exp.as_pyplot_figure()
plt.title('LIME Explanation')
plt.savefig('lime_explanation.png', dpi=300)
plt.show()

# Anchor explanation for a specific instance
explainer = anchor_tabular.AnchorTabularExplainer(
    class_names=['Low Risk', 'High Risk'],
    feature_names=X.columns,
    train_data=X_train_scaled
)

exp = explainer.explain_instance(X_test_scaled[instance_index], model.predict, threshold=0.95)

print('Anchor: %s' % (' AND '.join(exp.names())))
print('Precision: %.2f' % exp.precision())
print('Coverage: %.2f' % exp.coverage())